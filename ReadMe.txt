00combined_data.txt is our original DataSet 

01Feature_Extraction.ipynb and 02Model_Fitting.ipynb are our two Python Jupyter Notebook files 

NLP_Assignment_Application_v6.pdf is our Report

Top_Features.xlsx is a file generated by 02Model_Fitting.ipynb which is the voted importance of features

======================================================================

Required Installation:

beautifulsoup4
nltk
vaderSentiment
textstat
sklearn
imbalanced-learn (imblearn)
pandas
numpy
matplotlib
warnings
textblob
xgboost
lightgbm
bayes_opt

======================================================================

00combined_data.txt is a file that contains the informations of 8000 Amazon reviews
We are only interested in 4 fields from each review information: 
 
	'title',  is a String contains the text information of the title of the review

	'review_text', is a String contains the text information of the body of the review

	'helpful', is in the form of ‘A of B’, A is a integer stands for the number of users who clicked the ‘helpful’ button of this review, B is an integer stands for how many users had viewed this review

	'rating', categorical variable in {1.0, 2.0, 3.0, 4.0, 5.0}, which is the rating from the review writer towards the purchased item.
 ======================================================================

01Feature_Extraction.ipynb contains the python code to process the 00combined_data.txt file and output a new file ‘features.csv’
	Information Extraction:
		Extract the fields of interest of each review
	
	Normalize helpfulness rating:
		Set the threshold to 50%, if exceeds then helpful = 1, =0 otherwise

	Data clean:
		Remove review entries with missing data field

	Extract Stylometric Features for Title and Body:
		**List of Stylometric Features:**
		sentence_length, word_count, sentence_length_average, punctuation_count, emotive_language_count, capitalization_count, word_variety, numerical_data_presence

	Remove stop words
		
	Performing POS tagging, n-grams, sentiment analysis and subjectivity analysis
	
	File generation:
		Generate ‘features.csv’ which contains the 4 meta features and the extracted features

======================================================================
02Model_Fitting.ipynb have 4 main parts ：
	Feature Manipulation 
		Takes the ‘features.csv’ and conduct feature expansion and feature selection to generate the final training dataset ‘selected300.csv’
	
	Train Models
		Takes ‘selected300.csv’ as training dataset
		Use default hyper parameters to fit 6 models: XGBoost, LGBM, 
		LogisticRegression, SupportVectorMachine, RandomForestClassifier, Multi-
		Layer Perceptron Classifier. 

	Report Model Performance and Feature Importance
		Report the Accuracy, F2-score of the Models
		Report the voted importance of top 30 important features from each model 
		Save the report to Top_Features.xlsx

	Final Model Tuning and Performance report
		Use BayesianOptimization to fine tune the hyper parameter of LGBM
		Final fit of the LGBM model with the tuned hyper parameters

======================================================================

